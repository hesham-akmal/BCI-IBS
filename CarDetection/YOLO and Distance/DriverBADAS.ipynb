{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolo imports\n",
    "from __future__ import division\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import time\n",
    "import argparse\n",
    "import os \n",
    "import os.path as osp\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import random\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "from ConfidenceThresholdingAndNonMaximumSuppression import *\n",
    "from NeuralNetwork import *\n",
    "from Utilities import *\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Lane detection and distance estimation imports\n",
    "import glob\n",
    "from skimage import io, data\n",
    "import matplotlib.image as mpimg\n",
    "import camera_calibration\n",
    "import lane_detection\n",
    "import vanishing_point\n",
    "#import utilities\n",
    "import perspective_transform\n",
    "\n",
    "# YOLO code to be run only once ########################################################################################\n",
    "\n",
    "#Driver values\n",
    "\n",
    "images = 'imgs/'\n",
    "batch_size = 1\n",
    "confidence = 0.5\n",
    "nms_thesh = 0.4\n",
    "start = 0\n",
    "weights_file = 'yolov3.weights'\n",
    "cfg_file = 'cfg/yolov3.cfg'\n",
    "\n",
    "# weights_file = 'yolov3-tiny.weights'\n",
    "# cfg_file = 'cfg/yolov3-tiny.cfg'\n",
    "\n",
    "#Change cfg file and save\n",
    "def SetYoloReso(reso):\n",
    "    with open(cfg_file, \"r+\") as f:\n",
    "        lines = f.readlines()\n",
    "        del lines[3]\n",
    "        del lines[3]\n",
    "        lines.insert(3, 'height = ' + str(reso) + '\\n') \n",
    "        lines.insert(3, 'width = ' + str(reso) + '\\n') \n",
    "        f.seek(0)\n",
    "        f.truncate()\n",
    "        f.writelines(lines)\n",
    "        \n",
    "reso = 32*7\n",
    "SetYoloReso(reso)\n",
    "det = 'det/'\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "num_classes = 80    #For COCO\n",
    "classes = load_classes(\"data/coco.names\")\n",
    "\n",
    "######\n",
    "\n",
    "#Set up the neural network\n",
    "print(\"Loading network.....\")\n",
    "model = Darknet(cfg_file)\n",
    "model.load_weights(weights_file)\n",
    "print(\"Network successfully loaded\")\n",
    "\n",
    "model.net_info[\"height\"] = reso\n",
    "inp_dim = int(model.net_info[\"height\"])\n",
    "assert inp_dim % 32 == 0 \n",
    "assert inp_dim > 32\n",
    "\n",
    "#If there's a GPU availible, put the model on GPU\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "#Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Lane detection and distance estimation code to be run only once\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = camera_calibration.calibrate(False)\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# YOLO prediction function\n",
    "# Takes BGR image and returns: 1) image annotated with bounding boxes, 2) list of top left and bottom right\n",
    "# coordinates of bounding boxes, 3) list of class numbers which correspond to class labels\n",
    "\n",
    "def get_pred(img):\n",
    "    read_dir = time.time()\n",
    "    #Detection phase\n",
    "    imlist = ['img']\n",
    "\n",
    "    if not os.path.exists(det):\n",
    "        os.makedirs(det)\n",
    "\n",
    "    load_batch = time.time()\n",
    "    loaded_ims = [np.array(img)]\n",
    "#     loaded_ims = [cv2.undistort(np.array(img), mtx, dist, None, mtx)]\n",
    "    \n",
    "    #PyTorch Variables for images\n",
    "    im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))\n",
    "\n",
    "    #List containing dimensions of original images\n",
    "    im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
    "    im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
    "\n",
    "    if CUDA:\n",
    "        im_dim_list = im_dim_list.cuda()\n",
    "\n",
    "    leftover = 0\n",
    "    if (len(im_dim_list) % batch_size):\n",
    "        leftover = 1\n",
    "\n",
    "    if batch_size != 1:\n",
    "        num_batches = len(imlist) // batch_size + leftover            \n",
    "        im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size, len(im_batches))]))  for i in range(num_batches)]  \n",
    "\n",
    "    write = 0\n",
    "    start_det_loop = time.time()\n",
    "    \n",
    "    for i, batch in enumerate(im_batches):\n",
    "        #load the image \n",
    "        start = time.time()\n",
    "        t = time.time()  \n",
    "        if CUDA:\n",
    "            batch = batch.cuda()\n",
    "        with torch.no_grad():\n",
    "            prediction = model(Variable(batch), CUDA)\n",
    "#         print(\"prediction: \" , time.time()-t)    \n",
    "        t = time.time()    \n",
    "        prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
    "        end = time.time()\n",
    "\n",
    "        if type(prediction) == int:\n",
    "\n",
    "            for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
    "                im_id = i*batch_size + im_num\n",
    "#                 print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
    "#                 print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
    "#                 print(\"----------------------------------------------------------\")\n",
    "            continue\n",
    "\n",
    "        prediction[:,0] += i*batch_size    #transform the atribute from index in batch to index in imlist \n",
    "    \n",
    "    try:\n",
    "        if not write:                      #If we have't initialised output\n",
    "            output = prediction  \n",
    "            write = 1\n",
    "        else:\n",
    "            output = torch.cat((output,prediction))\n",
    "\n",
    "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
    "            im_id = i*batch_size + im_num\n",
    "            objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
    "#             print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
    "#             print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
    "#             print(\"----------------------------------------------------------\")\n",
    "\n",
    "        if CUDA:\n",
    "            torch.cuda.synchronize()\n",
    "#         output\n",
    "    except:\n",
    "        #print(\"exception\")\n",
    "        return loaded_ims[0]\n",
    "\n",
    "    im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n",
    "\n",
    "    scaling_factor = torch.min(inp_dim/im_dim_list,1)[0].view(-1,1)\n",
    "\n",
    "    output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n",
    "    output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2\n",
    "\n",
    "    output[:,1:5] /= scaling_factor\n",
    "\n",
    "    for i in range(output.shape[0]):\n",
    "        output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
    "        output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])\n",
    "\n",
    "    class_load = time.time()\n",
    "    colors = pkl.load(open(\"pallete\", \"rb\"))\n",
    "\n",
    "    draw = time.time()\n",
    "\n",
    "    list(map(lambda x: write_img(x, loaded_ims, color = random.choice(colors), classes = classes), output))\n",
    "\n",
    "    t = time.time()\n",
    "    det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(det,x.split(\"/\")[-1]))\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "#     print(\"SUMMARY\")\n",
    "###     print(\"----------------------------------------------------------\")\n",
    "###     print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
    "###     print()\n",
    "###     print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
    "###     print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
    "###     print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
    "#     print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
    "#     print(\"----------------------------------------------------------\")\n",
    "\n",
    "#     t = time.time()\n",
    "#     torch.cuda.empty_cache()\n",
    "#     print('= Time to torch.cuda.empty_cache : ', time.time() - t)\n",
    "   \n",
    "    return loaded_ims[0], output[:, 1:3], output[:, 3:5], output[:, -1]\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Perspective transform function.\n",
    "# Takes as input: 1) BGR image, 2) debug mode, 3) YOLO annotated image\n",
    "# Returns: 1) Homography matrix, 2) x pixels per meter, 3) y pixels per meter\n",
    "# To be called only one time one time on a base image, its outputs are then used for any image\n",
    "\n",
    "def driver_perspective_transform(img_BGR, debug=False):\n",
    "#     ud_img_BGR = cv2.undistort(img_BGR, mtx, dist, None, mtx)\n",
    "    ud_img_BGR = img_BGR\n",
    "    ud_img_RGB = cv2.cvtColor(ud_img_BGR, cv2.COLOR_BGR2RGB)\n",
    "    if(debug):\n",
    "        show_images([ud_img_RGB])\n",
    "    detector = lane_detection.LaneDetector()\n",
    "    lines = detector.process(ud_img_RGB, True, 0.5, 0.16, debug)\n",
    "    \n",
    "    vp = vanishing_point.calculate_vanishing_point(lines, ud_img_BGR, debug)\n",
    "    \n",
    "    H, H_inv, warped = perspective_transform.perspective_transform(vp, ud_img_BGR, debug)\n",
    "    \n",
    "    x_pixels_per_meter , y_pixels_per_meter, left_low, left_high, right_low, right_high = \\\n",
    "                    perspective_transform.get_ratio(H, H_inv, warped, mtx, debug)\n",
    "\n",
    "    return H, x_pixels_per_meter, y_pixels_per_meter\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Distance estimation function\n",
    "# Takes as input: 1) Query pixel, 2) Bottom center coordinates of screen, 3) homography matrix,\n",
    "# 4) x pixels per meter, 5) y pixels per meter\n",
    "# Returns distance to the query pixel\n",
    "def get_distance(query_pnt, center, H, x_pixels_per_meter, y_pixels_per_meter):\n",
    "    return perspective_transform.get_distance(query_pnt, center, H, x_pixels_per_meter, y_pixels_per_meter)\n",
    "\n",
    "#######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotates image with lanes or prints on image that lane departure is detected\n",
    "# Inputs: 1) image, 2) resolution of image / 1200x500 resolution\n",
    "# Outputs: 2) Annotated image\n",
    "\n",
    "def get_lane_image(img, ratio, debug=False):\n",
    "    base_left_m, base_left_c, base_right_m, base_right_c = -0.32785089597153977, 446.0614062879984*ratio,\\\n",
    "                                                            0.2911316010810115, 79.62376483613377*ratio\n",
    "    max_m_diff, max_c_diff = 0.13, 50\n",
    "\n",
    "    test_img = np.array(img)\n",
    "    width, height = test_img.shape[1], test_img.shape[0]\n",
    "\n",
    "    detector = lane_detection.LaneDetector()\n",
    "    lines = detector.process(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB), True, 0.4, 0.5, debug)\n",
    "\n",
    "    left_lane_lines, right_lane_lines = lane_detection.get_lane_lines(lines, base_left_m, base_left_c, base_right_m,\n",
    "                                                                      base_right_c, max_m_diff, max_c_diff)\n",
    "    if(len(left_lane_lines)==0 or len(right_lane_lines)==0):\n",
    "        inlane = True\n",
    "        cv2.putText(test_img,\n",
    "            \"Not inside lane\",\n",
    "            (int(width/2-150), 50), \n",
    "            font, \n",
    "            fontScale,\n",
    "            fontColor,\n",
    "            lineType)\n",
    "    else:\n",
    "        inlane = False\n",
    "        left_lane_line, right_lane_line = get_lines_mean(left_lane_lines), get_lines_mean(right_lane_lines)\n",
    "        low_y, high_y = height-1, int(height * 0.6)\n",
    "        left_low, left_high = (int((low_y-left_lane_line[1])/left_lane_line[0]), low_y),\\\n",
    "                              (int((high_y-left_lane_line[1])/left_lane_line[0]), high_y)\n",
    "        right_low, right_high = (int((low_y-right_lane_line[1])/right_lane_line[0]), low_y),\\\n",
    "                              (int((high_y-right_lane_line[1])/right_lane_line[0]), high_y)\n",
    "        cv2.line(test_img, tuple(left_low), tuple(left_high),(0,0,255),5)\n",
    "        cv2.line(test_img, tuple(right_low), tuple(right_high),(0,0,255),5)\n",
    "    \n",
    "    return test_img, inlane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Emergency braking fns\n",
    "import math\n",
    "import threading\n",
    "import time    \n",
    "# To play sounds\n",
    "import winsound\n",
    "\n",
    "last_t = time.time()\n",
    "last_dist = 0\n",
    "last_RV = 0\n",
    "last_VDi = 0\n",
    "\n",
    "Braking = False\n",
    "BrakeStartTime = time.time()\n",
    "\n",
    "def scale(val, src, dst):\n",
    "    return ((val - src[0]) / (src[1]-src[0])) * (dst[1]-dst[0]) + dst[0]\n",
    "\n",
    "def Brake3Secs():\n",
    "    global Braking\n",
    "    if(Braking):\n",
    "        return\n",
    "    Braking = True\n",
    "    BADAS_fns.StartFullBrake()\n",
    "    time.sleep(3)\n",
    "    Braking = False\n",
    "    BADAS_fns.StopBrake()\n",
    "\n",
    "def BrakeSystemUpdate(new_dist,CurTime,BrakeStartTime):\n",
    "    global Braking\n",
    "    if(Braking and (new_dist > 15 or CurTime - BrakeStartTime > 0.5) ):\n",
    "        print('StopBrake')\n",
    "        BADAS_fns.StopBrake()\n",
    "        Braking = False\n",
    "\n",
    "inlane = False\n",
    "WarningSnRunning = False\n",
    "def WarningSn():\n",
    "    global Braking\n",
    "    global inlane\n",
    "    global WarningSnRunning\n",
    "    global veh_speed\n",
    "    while(inlane):\n",
    "        print('veh_speed',veh_speed)\n",
    "        if(veh_speed > 5 and Braking == False):\n",
    "            winsound.Beep(300, 800)\n",
    "        time.sleep(0.5)\n",
    "    WarningSnRunning = False\n",
    "\n",
    "def LaneWarningControllerUpdate():\n",
    "    global inlane\n",
    "    global WarningSnRunning\n",
    "    if(inlane and WarningSnRunning == False):\n",
    "        WarningSnRunning = True\n",
    "        threading.Thread(target=WarningSn).start()\n",
    "\n",
    "def BrakeDecide(new_dist):\n",
    "    global BrakeStartTime\n",
    "    global Braking\n",
    "    global last_RV\n",
    "    global last_dist\n",
    "    global last_VDi\n",
    "    global last_t\n",
    "    \n",
    "    time_from_last_frame = time.time() - last_t\n",
    "    RV =  ( last_dist - new_dist ) / time_from_last_frame\n",
    "    RA = -( last_RV - RV) / time_from_last_frame\n",
    "    \n",
    "    VDi = veh_speed #BADAS_fns.client.getCarState().speed\n",
    "    VOi = VDi - RV\n",
    "    AD = (VDi - last_VDi) / time_from_last_frame\n",
    "    AO = AD - RA\n",
    "    \n",
    "    ###Set last frame vals\n",
    "    last_t = time.time()\n",
    "    last_dist = new_dist\n",
    "    last_RV = RV\n",
    "    last_VDi = VDi\n",
    "    \n",
    "    max_decel = 20\n",
    "    ds = ( VDi*VDi ) / (2*max_decel)\n",
    "    ts = VDi / max_decel\n",
    "    VOf = VOi + AO*ts\n",
    "    if(VOf >= 0):\n",
    "        do = ( VOi*ts ) + (0.5 * AO * (ts*ts))\n",
    "    else:\n",
    "        if(AO == 0):\n",
    "            do = 1000\n",
    "        else:\n",
    "            do = -(VOi * VOi) / (2 * AO)\n",
    "\n",
    "#     print('\\ndistance = ' , new_dist )\n",
    "#     print('time_from_last_frame = ' , time_from_last_frame )\n",
    "#     print('RV = ' , RV )\n",
    "#     print('RA = ' , RA )\n",
    "#     print('VDi = ' , VDi )\n",
    "#     print('VOi = ' , VOi )\n",
    "#     print('AD = ' , AD )\n",
    "#     print('AO = ' , AO )\n",
    "#     print('ds = ' , ds )\n",
    "#     print('ts = ' , ts )\n",
    "#     print('do = ' , do )\n",
    "#     print('(new_dist + do) - ds = ' , (new_dist + do) - ds )\n",
    "    \n",
    "    min_safe_dist = 8\n",
    "    X = (new_dist + do) - ds\n",
    "    \n",
    "    if( X <= 0 ):\n",
    "        prob = 1\n",
    "    elif( X >= min_safe_dist ):\n",
    "        prob = 0\n",
    "    else:\n",
    "        prob = scale(X , [0,min_safe_dist] , [1,0])\n",
    "    \n",
    "    print( 'prob: ' , prob )\n",
    "    \n",
    "    if( prob > 0.5 ):\n",
    "#         Brake3Secs()\n",
    "        if(Braking != True):\n",
    "            Braking = True\n",
    "            print('StartBrake')\n",
    "            BADAS_fns.StartFullBrake()\n",
    "            BrakeStartTime = time.time()\n",
    "    else:\n",
    "        BrakeSystemUpdate(new_dist, time.time(), BrakeStartTime)\n",
    "        \n",
    "#     print('rel time = ' , time.time() - t )\n",
    "#     if VisionEmergencyCheck(RA,RV,new_dist):\n",
    "#         threading.Thread(target=Brake2Secs).start()\n",
    "\n",
    "def ThresholdCheck(T):\n",
    "    print('T for collision: ', T)\n",
    "    if(T <= 0.65 and T > 0):\n",
    "#         if( T < 1 and T > 0.2 ):\n",
    "#             ManueverRight()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# a: 0.5 * acc\n",
    "# b: vel\n",
    "# c: -distance\n",
    "def VisionEmergencyCheck(acc, vel, dist):\n",
    "    if( vel < 0.001):\n",
    "        return False\n",
    "    \n",
    "    if( acc == 0 ):\n",
    "        return ThresholdCheck(dist/vel)\n",
    "    else:\n",
    "        a = 0.5 * acc\n",
    "        b = vel\n",
    "        c = -dist\n",
    "        \n",
    "        d = (b**2) - (4*a*c)\n",
    "        if(d<0):\n",
    "#             print('No collision (d<0)')\n",
    "            return False\n",
    "        \n",
    "        T = (-b+math.sqrt(d))/(2*a)\n",
    "        return ThresholdCheck(T)\n",
    "\n",
    "###################\n",
    "# SimConnectAndCheck()\n",
    "# while True:\n",
    "#     time.sleep(0.2)\n",
    "#     prob = BrakeDecide((BADAS_fns.client.getAdasPacket())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################################################################\n",
    "# Importing Airsim\n",
    "# Uses local airsim package (DO NOT pip install, UNINSTALL IF INSTALLED ALREADY: \"pip uninstall airsim\")\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from ctypes import *\n",
    "sys.path.append(str(Path().resolve().parent.parent).replace('\\\\','/') + '/AirSimClient')\n",
    "os.environ['PATH'] = str(Path().resolve().parent.parent).replace('\\\\','/') + '/AirSimClient' + os.pathsep + os.environ['PATH']\n",
    "d = CDLL('SDL2.dll') #Steering kit haptic feedback dll\n",
    "import BADAS_fns\n",
    "\n",
    "#If changed, Sim must be restarted to take effect\n",
    "BADAS_fns.SetSimImgRes(500,208)\n",
    "# SetSimImgRes(1200,500)\n",
    "# SetSimImgRes(1440,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sim Real-time distance detection and showing output using CV2\n",
    "\n",
    "#Connect/Reconnect\n",
    "BADAS_fns.SimConnectAndCheck()\n",
    "\n",
    "# Braking = False\n",
    "##################################################################################################################################################################\n",
    "\n",
    "def crop_center(img,cropx,cropy):\n",
    "    y,x,z = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "# Preparing text style that will be used in writing distances\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "pos = (0,0)\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2\n",
    "\n",
    "img = cv2.imread('imgs/noshade1200x500.JPG')\n",
    "H, x_pixels_per_meter, y_pixels_per_meter = driver_perspective_transform(img, False)\n",
    "\n",
    "#Calculate distance accuracy \n",
    "# dist_lst1 = []\n",
    "# tott_lst = []\n",
    "\n",
    "drawDebug = True\n",
    "printDebug = True\n",
    "\n",
    "while True:\n",
    "    # Press \"q\" to quit\n",
    "    if drawDebug and cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "    t3 = time.time()\n",
    "    t1 = t3\n",
    "    \n",
    "    veh_speed = BADAS_fns.client.getCarState().speed\n",
    "    \n",
    "    try:\n",
    "        img = BADAS_fns.GetSimImg()\n",
    "        if(drawDebug):\n",
    "            cv2.imshow(\"\", img)\n",
    "        if(printDebug):\n",
    "            print('T Sim image extract: ' , time.time() - t1)\n",
    "    except:\n",
    "        print('GetSimImg Exception ')\n",
    "        continue\n",
    "    \n",
    "    # Image bottom center coordinates\n",
    "    center = [img.shape[1]//2, img.shape[0]-1]\n",
    "    \n",
    "    try:\n",
    "        t1 = time.time()\n",
    "        img, inlane = get_lane_image(img, float(img.shape[0])/500)\n",
    "        LaneWarningControllerUpdate()\n",
    "            \n",
    "        if(printDebug):\n",
    "            print('T get_lane_image: ' , time.time() - t1)\n",
    "        \n",
    "        imgYOLO = crop_center(img,208,208)\n",
    "        \n",
    "        if(drawDebug):\n",
    "            cv2.imshow(\"\", img)\n",
    "        # Getting predictions from yolo\n",
    "        t1 = time.time()\n",
    "        pred, top_left, bottom_right, labels = get_pred(imgYOLO)\n",
    "        if(printDebug):\n",
    "            print('T Yolo: ' , time.time() - t1)\n",
    "    except:\n",
    "        print('YException ')\n",
    "        continue\n",
    "    \n",
    "#     failed getting distance from yolo box size\n",
    "#     BoxXdist = math.sqrt( (top_left[0][1] - top_left[0][0])**2 + (bottom_right[0][0] - bottom_right[0][1])**2 )\n",
    "#     print('BoxXdist',BoxXdist)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    # Looping on every detected object\n",
    "    for i in range(len(labels)):\n",
    "        # Object label\n",
    "        label = classes[int(labels[i])]\n",
    "\n",
    "        if(label != \"car\"):\n",
    "            continue\n",
    "\n",
    "        # Top left x,y\n",
    "        tlx, tly = int(top_left[i,0]), int(top_left[i,1])\n",
    "\n",
    "        # Bottom right x,y\n",
    "        brx, bry = int(bottom_right[i,0]), int(bottom_right[i,1])\n",
    "\n",
    "        # Bottom center coordinates of bounding box\n",
    "        cx, cy = (tlx + brx)//2, bry\n",
    "\n",
    "        #print(str(cx) + \",\" + str(cy) + \" | \" + str(center[0]) + \",\" + str(center[1]))\n",
    "\n",
    "        # Distance to car\n",
    "        float_dist = get_distance(scale_pixel([cx, cy], img.shape), scale_pixel(center, img.shape), H, x_pixels_per_meter, y_pixels_per_meter)\n",
    "\n",
    "        #Mapping distance\n",
    "#         float_dist = scale(float_dist, (3.1587, 31) , (3.7459, 27.7)) #From height500 imgs\n",
    "\n",
    "        EmergencyBool = BrakeDecide(float_dist)\n",
    "        \n",
    "#         try:\n",
    "#             # Extract distance from sim #########################\n",
    "#             actual_dist = BADAS_fns.client.getAdasPacket()[1]\n",
    "#             dist_lst1.append( abs(actual_dist - float_dist) )\n",
    "#             print('actual dist: ' , actual_dist)\n",
    "#             print('estimated dist: ' , float_dist)\n",
    "#         except:\n",
    "#             print('Extract distance from sim except')\n",
    "#             pass\n",
    "        ############################################################\n",
    "        if(drawDebug):\n",
    "            dtime = time.time()\n",
    "            #paste yolo img on lane img\n",
    "            img[0:pred.shape[0] , 146:146 + pred.shape[1]] = pred\n",
    "#             img[0:pred.shape[0] , 350:350 + pred.shape[1]] = pred\n",
    "            distance = str(round_float(float_dist))+\"m\"\n",
    "            if(EmergencyBool):\n",
    "                cv2.putText(img, \"EMERGENCY\",(cx-60+146, cy-60), font, fontScale,fontColor, lineType)\n",
    "           # Annotate yolo image with distance to car\n",
    "            cv2.putText(img, distance, (cx-60+146, cy+30), font, fontScale, fontColor, lineType)\n",
    "            if(printDebug):\n",
    "                print('T Get distance: ' , time.time() - t1)\n",
    "            #print(x_pixels_per_meter)\n",
    "            #print(y_pixels_per_meter)\n",
    "            cv2.imshow(\"\", img)\n",
    "            if(printDebug):\n",
    "                print('T Debug Draw: ' , time.time() - dtime)\n",
    "#     tott_lst.append(time.time() - t3)\n",
    "    if(printDebug):\n",
    "        print('T Total: ' , time.time() - t3 , '\\n')\n",
    "        print('FrameEnd\\n')\n",
    "\n",
    "# print('num: ' , len(dist_lst1))\n",
    "# print(\"dist mean absolute error: \", sum(dist_lst1) / len(dist_lst1) )\n",
    "# print(\"Tott avg: \", sum(tott_lst) / len(tott_lst) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolo imports\n",
    "from __future__ import division\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import time\n",
    "import argparse\n",
    "import os \n",
    "import os.path as osp\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import random\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "from ConfidenceThresholdingAndNonMaximumSuppression import *\n",
    "from NeuralNetwork import *\n",
    "from Utilities import *\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Lane detection and distance estimation imports\n",
    "import glob\n",
    "from skimage import io, data\n",
    "import matplotlib.image as mpimg\n",
    "import camera_calibration\n",
    "import lane_detection\n",
    "import vanishing_point\n",
    "#import utilities\n",
    "import perspective_transform\n",
    "\n",
    "# YOLO code to be run only once ########################################################################################\n",
    "\n",
    "#Driver values\n",
    "\n",
    "images = 'imgs/'\n",
    "batch_size = 1\n",
    "confidence = 0.5\n",
    "nms_thesh = 0.4\n",
    "start = 0\n",
    "weights_file = 'yolov3.weights'\n",
    "cfg_file = 'cfg/yolov3.cfg'\n",
    "\n",
    "# weights_file = 'yolov3-tiny.weights'\n",
    "# cfg_file = 'cfg/yolov3-tiny.cfg'\n",
    "\n",
    "#Change cfg file and save\n",
    "def SetYoloReso(reso):\n",
    "    with open(cfg_file, \"r+\") as f:\n",
    "        lines = f.readlines()\n",
    "        del lines[3]\n",
    "        del lines[3]\n",
    "        lines.insert(3, 'height = ' + str(reso) + '\\n') \n",
    "        lines.insert(3, 'width = ' + str(reso) + '\\n') \n",
    "        f.seek(0)\n",
    "        f.truncate()\n",
    "        f.writelines(lines)\n",
    "        \n",
    "reso = 32*7\n",
    "SetYoloReso(reso)\n",
    "det = 'det/'\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "num_classes = 80    #For COCO\n",
    "classes = load_classes(\"data/coco.names\")\n",
    "\n",
    "######\n",
    "\n",
    "#Set up the neural network\n",
    "print(\"Loading network.....\")\n",
    "model = Darknet(cfg_file)\n",
    "model.load_weights(weights_file)\n",
    "print(\"Network successfully loaded\")\n",
    "\n",
    "model.net_info[\"height\"] = reso\n",
    "inp_dim = int(model.net_info[\"height\"])\n",
    "assert inp_dim % 32 == 0 \n",
    "assert inp_dim > 32\n",
    "\n",
    "#If there's a GPU availible, put the model on GPU\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "#Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Lane detection and distance estimation code to be run only once\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = camera_calibration.calibrate(False)\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# YOLO prediction function\n",
    "# Takes BGR image and returns: 1) image annotated with bounding boxes, 2) list of top left and bottom right\n",
    "# coordinates of bounding boxes, 3) list of class numbers which correspond to class labels\n",
    "\n",
    "def get_pred(img):\n",
    "    read_dir = time.time()\n",
    "    #Detection phase\n",
    "    imlist = ['img']\n",
    "\n",
    "    if not os.path.exists(det):\n",
    "        os.makedirs(det)\n",
    "\n",
    "    load_batch = time.time()\n",
    "    loaded_ims = [np.array(img)]\n",
    "#     loaded_ims = [cv2.undistort(np.array(img), mtx, dist, None, mtx)]\n",
    "    \n",
    "    #PyTorch Variables for images\n",
    "    im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))\n",
    "\n",
    "    #List containing dimensions of original images\n",
    "    im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
    "    im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
    "\n",
    "    if CUDA:\n",
    "        im_dim_list = im_dim_list.cuda()\n",
    "\n",
    "    leftover = 0\n",
    "    if (len(im_dim_list) % batch_size):\n",
    "        leftover = 1\n",
    "\n",
    "    if batch_size != 1:\n",
    "        num_batches = len(imlist) // batch_size + leftover            \n",
    "        im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size, len(im_batches))]))  for i in range(num_batches)]  \n",
    "\n",
    "    write = 0\n",
    "    start_det_loop = time.time()\n",
    "    \n",
    "    for i, batch in enumerate(im_batches):\n",
    "        #load the image \n",
    "        start = time.time()\n",
    "        t = time.time()  \n",
    "        if CUDA:\n",
    "            batch = batch.cuda()\n",
    "        with torch.no_grad():\n",
    "            prediction = model(Variable(batch), CUDA)\n",
    "#         print(\"prediction: \" , time.time()-t)    \n",
    "        t = time.time()    \n",
    "        prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
    "        end = time.time()\n",
    "\n",
    "        if type(prediction) == int:\n",
    "\n",
    "            for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
    "                im_id = i*batch_size + im_num\n",
    "#                 print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
    "#                 print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
    "#                 print(\"----------------------------------------------------------\")\n",
    "            continue\n",
    "\n",
    "        prediction[:,0] += i*batch_size    #transform the atribute from index in batch to index in imlist \n",
    "    \n",
    "    try:\n",
    "        if not write:                      #If we have't initialised output\n",
    "            output = prediction  \n",
    "            write = 1\n",
    "        else:\n",
    "            output = torch.cat((output,prediction))\n",
    "\n",
    "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
    "            im_id = i*batch_size + im_num\n",
    "            objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
    "#             print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
    "#             print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
    "#             print(\"----------------------------------------------------------\")\n",
    "\n",
    "        if CUDA:\n",
    "            torch.cuda.synchronize()\n",
    "#         output\n",
    "    except:\n",
    "        #print(\"exception\")\n",
    "        return loaded_ims[0]\n",
    "\n",
    "    im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n",
    "\n",
    "    scaling_factor = torch.min(inp_dim/im_dim_list,1)[0].view(-1,1)\n",
    "\n",
    "    output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n",
    "    output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2\n",
    "\n",
    "    output[:,1:5] /= scaling_factor\n",
    "\n",
    "    for i in range(output.shape[0]):\n",
    "        output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
    "        output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])\n",
    "\n",
    "    class_load = time.time()\n",
    "    colors = pkl.load(open(\"pallete\", \"rb\"))\n",
    "\n",
    "    draw = time.time()\n",
    "\n",
    "    list(map(lambda x: write_img(x, loaded_ims, color = random.choice(colors), classes = classes), output))\n",
    "\n",
    "    t = time.time()\n",
    "    det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(det,x.split(\"/\")[-1]))\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "#     print(\"SUMMARY\")\n",
    "###     print(\"----------------------------------------------------------\")\n",
    "###     print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
    "###     print()\n",
    "###     print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
    "###     print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
    "###     print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
    "#     print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
    "#     print(\"----------------------------------------------------------\")\n",
    "\n",
    "#     t = time.time()\n",
    "#     torch.cuda.empty_cache()\n",
    "#     print('= Time to torch.cuda.empty_cache : ', time.time() - t)\n",
    "   \n",
    "    return loaded_ims[0], output[:, 1:3], output[:, 3:5], output[:, -1]\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Perspective transform function.\n",
    "# Takes as input: 1) BGR image, 2) debug mode, 3) YOLO annotated image\n",
    "# Returns: 1) Homography matrix, 2) x pixels per meter, 3) y pixels per meter\n",
    "# To be called only one time one time on a base image, its outputs are then used for any image\n",
    "\n",
    "def driver_perspective_transform(img_BGR, debug=False):\n",
    "#     ud_img_BGR = cv2.undistort(img_BGR, mtx, dist, None, mtx)\n",
    "    ud_img_BGR = img_BGR\n",
    "    ud_img_RGB = cv2.cvtColor(ud_img_BGR, cv2.COLOR_BGR2RGB)\n",
    "    if(debug):\n",
    "        show_images([ud_img_RGB])\n",
    "    detector = lane_detection.LaneDetector()\n",
    "    lines = detector.process(ud_img_RGB, True, 0.5, 0.16, debug)\n",
    "    \n",
    "    vp = vanishing_point.calculate_vanishing_point(lines, ud_img_BGR, debug)\n",
    "    \n",
    "    H, H_inv, warped = perspective_transform.perspective_transform(vp, ud_img_BGR, debug)\n",
    "    \n",
    "    x_pixels_per_meter , y_pixels_per_meter, left_low, left_high, right_low, right_high = \\\n",
    "                    perspective_transform.get_ratio(H, H_inv, warped, mtx, debug)\n",
    "\n",
    "    return H, x_pixels_per_meter, y_pixels_per_meter\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Distance estimation function\n",
    "# Takes as input: 1) Query pixel, 2) Bottom center coordinates of screen, 3) homography matrix,\n",
    "# 4) x pixels per meter, 5) y pixels per meter\n",
    "# Returns distance to the query pixel\n",
    "def get_distance(query_pnt, center, H, x_pixels_per_meter, y_pixels_per_meter):\n",
    "    return perspective_transform.get_distance(query_pnt, center, H, x_pixels_per_meter, y_pixels_per_meter)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Annotates image with lanes or prints on image that lane departure is detected\n",
    "# Inputs: 1) image, 2) resolution of image / 1200x500 resolution\n",
    "# Outputs: 2) Annotated image\n",
    "\n",
    "def get_lane_image(img, ratio, debug=False):\n",
    "    base_left_m, base_left_c, base_right_m, base_right_c = -0.32785089597153977, 446.0614062879984*ratio,\\\n",
    "                                                            0.2911316010810115, 79.62376483613377*ratio\n",
    "    max_m_diff, max_c_diff = 0.13, 50\n",
    "\n",
    "    test_img = np.array(img)\n",
    "    width, height = test_img.shape[1], test_img.shape[0]\n",
    "\n",
    "    detector = lane_detection.LaneDetector()\n",
    "    lines = detector.process(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB), True, 0.4, 0.5, debug)\n",
    "\n",
    "    left_lane_lines, right_lane_lines = lane_detection.get_lane_lines(lines, base_left_m, base_left_c, base_right_m,\n",
    "                                                                      base_right_c, max_m_diff, max_c_diff)\n",
    "    if(len(left_lane_lines)==0 or len(right_lane_lines)==0):\n",
    "        inlane = True\n",
    "        cv2.putText(test_img,\n",
    "            \"Not inside lane\",\n",
    "            (int(width/2-150), 50), \n",
    "            font, \n",
    "            fontScale,\n",
    "            fontColor,\n",
    "            lineType)\n",
    "    else:\n",
    "        inlane = False\n",
    "        left_lane_line, right_lane_line = get_lines_mean(left_lane_lines), get_lines_mean(right_lane_lines)\n",
    "        low_y, high_y = height-1, int(height * 0.6)\n",
    "        left_low, left_high = (int((low_y-left_lane_line[1])/left_lane_line[0]), low_y),\\\n",
    "                              (int((high_y-left_lane_line[1])/left_lane_line[0]), high_y)\n",
    "        right_low, right_high = (int((low_y-right_lane_line[1])/right_lane_line[0]), low_y),\\\n",
    "                              (int((high_y-right_lane_line[1])/right_lane_line[0]), high_y)\n",
    "        cv2.line(test_img, tuple(left_low), tuple(left_high),(0,0,255),5)\n",
    "        cv2.line(test_img, tuple(right_low), tuple(right_high),(0,0,255),5)\n",
    "    \n",
    "    return test_img, inlane\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "##Emergency braking fns\n",
    "import math\n",
    "import threading\n",
    "import time    \n",
    "# To play sounds\n",
    "import winsound\n",
    "\n",
    "last_t = time.time()\n",
    "last_dist = 0\n",
    "last_RV = 0\n",
    "last_VDi = 0\n",
    "\n",
    "Braking = False\n",
    "BrakeStartTime = time.time()\n",
    "\n",
    "def scale(val, src, dst):\n",
    "    return ((val - src[0]) / (src[1]-src[0])) * (dst[1]-dst[0]) + dst[0]\n",
    "\n",
    "def Brake3Secs():\n",
    "    global Braking\n",
    "    if(Braking):\n",
    "        return\n",
    "    Braking = True\n",
    "    BADAS_fns.StartFullBrake()\n",
    "    time.sleep(3)\n",
    "    Braking = False\n",
    "    BADAS_fns.StopBrake()\n",
    "\n",
    "def BrakeSystemUpdate(new_dist,CurTime,BrakeStartTime):\n",
    "    global Braking\n",
    "    if(Braking and (new_dist > 15 or CurTime - BrakeStartTime > 0.5) ):\n",
    "        print('StopBrake')\n",
    "        BADAS_fns.StopBrake()\n",
    "        Braking = False\n",
    "\n",
    "inlane = False\n",
    "WarningSnRunning = False\n",
    "def WarningSn():\n",
    "    global Braking\n",
    "    global inlane\n",
    "    global WarningSnRunning\n",
    "    global veh_speed\n",
    "    while(inlane):\n",
    "        print('veh_speed',veh_speed)\n",
    "        if(veh_speed > 5 and Braking == False):\n",
    "            winsound.Beep(300, 800)\n",
    "        time.sleep(0.5)\n",
    "    WarningSnRunning = False\n",
    "\n",
    "def LaneWarningControllerUpdate():\n",
    "    global inlane\n",
    "    global WarningSnRunning\n",
    "    if(inlane and WarningSnRunning == False):\n",
    "        WarningSnRunning = True\n",
    "        threading.Thread(target=WarningSn).start()\n",
    "\n",
    "def BrakeDecide(new_dist):\n",
    "    global BrakeStartTime\n",
    "    global Braking\n",
    "    global last_RV\n",
    "    global last_dist\n",
    "    global last_VDi\n",
    "    global last_t\n",
    "    \n",
    "    time_from_last_frame = time.time() - last_t\n",
    "    RV =  ( last_dist - new_dist ) / time_from_last_frame\n",
    "    RA = -( last_RV - RV) / time_from_last_frame\n",
    "    \n",
    "    VDi = veh_speed #BADAS_fns.client.getCarState().speed\n",
    "    VOi = VDi - RV\n",
    "    AD = (VDi - last_VDi) / time_from_last_frame\n",
    "    AO = AD - RA\n",
    "    \n",
    "    ###Set last frame vals\n",
    "    last_t = time.time()\n",
    "    last_dist = new_dist\n",
    "    last_RV = RV\n",
    "    last_VDi = VDi\n",
    "    \n",
    "    max_decel = 20\n",
    "    ds = ( VDi*VDi ) / (2*max_decel)\n",
    "    ts = VDi / max_decel\n",
    "    VOf = VOi + AO*ts\n",
    "    if(VOf >= 0):\n",
    "        do = ( VOi*ts ) + (0.5 * AO * (ts*ts))\n",
    "    else:\n",
    "        if(AO == 0):\n",
    "            do = 1000\n",
    "        else:\n",
    "            do = -(VOi * VOi) / (2 * AO)\n",
    "\n",
    "#     print('\\ndistance = ' , new_dist )\n",
    "#     print('time_from_last_frame = ' , time_from_last_frame )\n",
    "#     print('RV = ' , RV )\n",
    "#     print('RA = ' , RA )\n",
    "#     print('VDi = ' , VDi )\n",
    "#     print('VOi = ' , VOi )\n",
    "#     print('AD = ' , AD )\n",
    "#     print('AO = ' , AO )\n",
    "#     print('ds = ' , ds )\n",
    "#     print('ts = ' , ts )\n",
    "#     print('do = ' , do )\n",
    "#     print('(new_dist + do) - ds = ' , (new_dist + do) - ds )\n",
    "    \n",
    "    min_safe_dist = 8\n",
    "    X = (new_dist + do) - ds\n",
    "    \n",
    "    if( X <= 0 ):\n",
    "        prob = 1\n",
    "    elif( X >= min_safe_dist ):\n",
    "        prob = 0\n",
    "    else:\n",
    "        prob = scale(X , [0,min_safe_dist] , [1,0])\n",
    "    \n",
    "    return prob\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Sim Real-time distance detection and showing output using CV2\n",
    "\n",
    "#Connect/Reconnect\n",
    "BADAS_fns.SimConnectAndCheck()\n",
    "\n",
    "# Braking = False\n",
    "##################################################################################################################################################################\n",
    "\n",
    "def crop_center(img,cropx,cropy):\n",
    "    y,x,z = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "# Preparing text style that will be used in writing distances\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "pos = (0,0)\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2\n",
    "\n",
    "img = cv2.imread('imgs/noshade1200x500.JPG')\n",
    "H, x_pixels_per_meter, y_pixels_per_meter = driver_perspective_transform(img, False)\n",
    "\n",
    "#Calculate distance accuracy \n",
    "# dist_lst1 = []\n",
    "# tott_lst = []\n",
    "\n",
    "drawDebug = False\n",
    "printDebug = True\n",
    "\n",
    "def EstimateDistance():\n",
    "    prob = -1\n",
    "    t3 = time.time()\n",
    "    t1 = t3\n",
    "    \n",
    "    veh_speed = BADAS_fns.client.getCarState().speed\n",
    "    \n",
    "    try:\n",
    "        img = BADAS_fns.GetSimImg()\n",
    "        if(drawDebug):\n",
    "            cv2.imshow(\"\", img)\n",
    "        if(printDebug):\n",
    "            print('T Sim image extract: ' , time.time() - t1)\n",
    "    except:\n",
    "        print('GetSimImg Exception ')\n",
    "        return prob\n",
    "    \n",
    "    # Image bottom center coordinates\n",
    "    center = [img.shape[1]//2, img.shape[0]-1]\n",
    "    \n",
    "    try:\n",
    "        t1 = time.time()\n",
    "        img, inlane = get_lane_image(img, float(img.shape[0])/500)\n",
    "        LaneWarningControllerUpdate()\n",
    "            \n",
    "        if(printDebug):\n",
    "            print('T get_lane_image: ' , time.time() - t1)\n",
    "        \n",
    "        imgYOLO = crop_center(img,208,208)\n",
    "        \n",
    "        if(drawDebug):\n",
    "            cv2.imshow(\"\", img)\n",
    "        # Getting predictions from yolo\n",
    "        t1 = time.time()\n",
    "        pred, top_left, bottom_right, labels = get_pred(imgYOLO)\n",
    "        if(printDebug):\n",
    "            print('T Yolo: ' , time.time() - t1)\n",
    "    except:\n",
    "        print('YException ')\n",
    "        return prob\n",
    "    \n",
    "#     failed getting distance from yolo box size\n",
    "#     BoxXdist = math.sqrt( (top_left[0][1] - top_left[0][0])**2 + (bottom_right[0][0] - bottom_right[0][1])**2 )\n",
    "#     print('BoxXdist',BoxXdist)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    # Looping on every detected object\n",
    "    for i in range(len(labels)):\n",
    "        # Object label\n",
    "        label = classes[int(labels[i])]\n",
    "\n",
    "        if(label != \"car\"):\n",
    "            continue\n",
    "\n",
    "        # Top left x,y\n",
    "        tlx, tly = int(top_left[i,0]), int(top_left[i,1])\n",
    "\n",
    "        # Bottom right x,y\n",
    "        brx, bry = int(bottom_right[i,0]), int(bottom_right[i,1])\n",
    "\n",
    "        # Bottom center coordinates of bounding box\n",
    "        cx, cy = (tlx + brx)//2, bry\n",
    "\n",
    "        # Distance to car\n",
    "        float_dist = get_distance(scale_pixel([cx, cy], img.shape), scale_pixel(center, img.shape), H, x_pixels_per_meter, y_pixels_per_meter)\n",
    "\n",
    "        prob = BrakeDecide(float_dist)\n",
    "        \n",
    "        if(drawDebug):\n",
    "            dtime = time.time()\n",
    "            #paste yolo img on lane img\n",
    "            img[0:pred.shape[0] , 146:146 + pred.shape[1]] = pred\n",
    "            distance = str(round_float(float_dist))+\"m\"\n",
    "#             if(EmergencyBool):\n",
    "#                 cv2.putText(img, \"EMERGENCY\",(cx-60+146, cy-60), font, fontScale,fontColor, lineType)\n",
    "           # Annotate yolo image with distance to car\n",
    "            cv2.putText(img, distance, (cx-60+146, cy+30), font, fontScale, fontColor, lineType)\n",
    "            if(printDebug):\n",
    "                print('T Get distance: ' , time.time() - t1)\n",
    "            cv2.imshow(\"\", img)\n",
    "            if(printDebug):\n",
    "                print('T Debug Draw: ' , time.time() - dtime)\n",
    "    if(printDebug):\n",
    "        print('T Total: ' , time.time() - t3 , '\\n')\n",
    "        print('FrameEnd\\n')\n",
    "        \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(EstimateDistance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading image\n",
    "img = cv2.imread('imgs/noshade1200x500.JPG')\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "# Image bottom center coordinates\n",
    "center = [img.shape[1]//2, img.shape[0]-1]\n",
    "\n",
    "# Preparing text style that will be used in writing distances\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "pos = (0,0)\n",
    "fontScale              = 1\n",
    "fontColor              = (0,0,0)\n",
    "lineType               = 2\n",
    "\n",
    "# Getting predictions from yolo\n",
    "pred, top_left, bottom_right, labels = get_pred(img)\n",
    "    \n",
    "# Perform perspective transform and annotate yolo image\n",
    "H, x_pixels_per_meter, y_pixels_per_meter = driver_perspective_transform(img, True)\n",
    "\n",
    "# Looping on every detected object\n",
    "for i in range(len(labels)):\n",
    "    \n",
    "    # Object label\n",
    "    label = classes[int(labels[i])]\n",
    "    \n",
    "    if(label != \"car\"):\n",
    "        continue\n",
    "        \n",
    "    # Top left x,y\n",
    "    tlx, tly = int(top_left[i,0]), int(top_left[i,1])\n",
    "    \n",
    "    # Bottom right x,y\n",
    "    brx, bry = int(bottom_right[i,0]), int(bottom_right[i,1])\n",
    "        \n",
    "    # Bottom center coordinates of bounding box\n",
    "    cx, cy = (tlx + brx)//2, bry\n",
    "    \n",
    "    print(str(cx) + \",\" + str(cy) + \" | \" + str(center[0]) + \",\" + str(center[1]))\n",
    "    \n",
    "    # Distance to car\n",
    "    float_dist = get_distance([cx, cy], center, H, x_pixels_per_meter, y_pixels_per_meter)\n",
    "\n",
    "    distance = str(round_float(float_dist))+\"m\"\n",
    "    \n",
    "    # Annotate yolo image with distance to car\n",
    "    cv2.putText(pred,\n",
    "        distance,\n",
    "        (cx-60, cy+30), \n",
    "        font, \n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        lineType)\n",
    "\n",
    "print(x_pixels_per_meter)\n",
    "print(y_pixels_per_meter)\n",
    "    \n",
    "show_images([cv2.cvtColor(pred, cv2.COLOR_BGR2RGB)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img1 = cv2.imread('imgs/1202x498.jpg')\n",
    "out_img1 = get_lane_image(test_img1, 1)\n",
    "show_images([cv2.cvtColor(out_img1, cv2.COLOR_BGR2RGB)])\n",
    "\n",
    "test_img2 = cv2.imread('imgs/noshade500x208.jpg')\n",
    "out_img2 = get_lane_image(test_img2, 500/1200.0)\n",
    "show_images([cv2.cvtColor(out_img2, cv2.COLOR_BGR2RGB)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "directory = os.fsencode(\"images1\")\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        test_img = cv2.imread(\"images1/\"+filename)\n",
    "        out_img = get_lane_image(test_img, float(test_img.shape[0])/500)\n",
    "        cv2.imwrite(\"out_images1/out\"+str(cnt)+\".jpg\", out_img)\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "#BADAS v2.6+\n",
    "def SteerByAngle(angle, direction):\n",
    "    \n",
    "    FirstVec = BADAS_fns.client.getSuvFwdVec() #Get first forward vector\n",
    "    \n",
    "    car_controls = BADAS_fns.airsim.CarControls()\n",
    "    \n",
    "    car_controls.throttle = 0 # Change later, need to meet certain velocity depending on manuever equation\n",
    "    \n",
    "    if(direction == 'right'):\n",
    "        car_controls.steering = 1\n",
    "    elif(direction == 'left'):\n",
    "        car_controls.steering = -1\n",
    "        \n",
    "    #Start steering    \n",
    "    BADAS_fns.client.enableApiControl(True)  \n",
    "    BADAS_fns.client.setCarControls(car_controls)\n",
    "    \n",
    "    #Keep steering until required angle is met\n",
    "    while (True):\n",
    "        SecVec = BADAS_fns.client.getSuvFwdVec()\n",
    "        radians = angle_between( (FirstVec['X'], FirstVec['Y']), (SecVec['X'], SecVec['Y'])) #Get angle betwen first and second forward vectors\n",
    "        \n",
    "        if(math.degrees(radians) >= angle): #Stop steering if required angle is met\n",
    "            break\n",
    "        \n",
    "        if(BADAS_fns.client.getCarState().speed < 1): #Stop steering in case of errors\n",
    "            break\n",
    "            \n",
    "        time.sleep(0.01)\n",
    "        \n",
    "    BADAS_fns.client.enableApiControl(False) # Return driver full controls\n",
    "\n",
    "def ManueverRight():\n",
    "    SteerByAngle(20,'right')\n",
    "    time.sleep(0.1)   \n",
    "    SteerByAngle(20,'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        #starttime = time.time()\n",
    "        t = time.time()\n",
    "        responses = client.simGetImages([ airsim.ImageRequest(\"0\", airsim.ImageType.Scene, False, False) ])\n",
    "        response = responses[0]\n",
    "        img1d = np.frombuffer(response.image_data_uint8, dtype=np.uint8) \n",
    "        img_rgba = img1d.reshape(response.height, response.width, 4)  \n",
    "        img_rgba = cv2.resize(img_rgba, dsize=(256, 128), interpolation=cv2.INTER_NEAREST) #####################RESIZING FOR FAST PREDICTION\n",
    "        print('= T Extract sim image: ' , time.time()-t)\n",
    "\n",
    "        t = time.time()\n",
    "        detected = get_pred(img_rgba)\n",
    "        print('= T Detecting: ' , time.time()-t)\n",
    "        \n",
    "        cv2.imshow(\"img\", detected)\n",
    "        #print('=== TOTAL TIME ' , time.time()-starttime , ' ===\\n')\n",
    "        \n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "except:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "x = 100\n",
    "while True:\n",
    "    x = x -1\n",
    "    if x < 0:\n",
    "        break\n",
    "    t = time.time()\n",
    "    png_image = client.simGetImage(\"1\", airsim.ImageType.Scene)\n",
    "    print('time: ' , time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = BADAS_fns.client.simGetImages([ BADAS_fns.airsim.ImageRequest(\"0\", BADAS_fns.airsim.ImageType.Scene, False, False) ])\n",
    "response = responses[0]\n",
    "img1d = np.fromstring(response.image_data_uint8, dtype=np.uint8) \n",
    "img = img1d.reshape(response.height, response.width, 4)  \n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print average of time to detect img and predict\n",
    "timeout = time.time() + 3 #5 secs\n",
    "\n",
    "lst = [] \n",
    "lst2 = [] \n",
    "\n",
    "while True:\n",
    "    if time.time() > timeout:\n",
    "        break\n",
    "    start = time.time()\n",
    "    responses = BADAS_fns.client.simGetImages([ BADAS_fns.airsim.ImageRequest(\"0\", BADAS_fns.airsim.ImageType.Scene, False, False) ])\n",
    "    response = responses[0]\n",
    "    img1d = np.fromstring(response.image_data_uint8, dtype=np.uint8) \n",
    "    img = img1d.reshape(response.height, response.width, 4)  \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    print(\"T SimGetImg =\", time.time() - start ) \n",
    "    lst2.append(time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    detected = get_pred(img)\n",
    "    print(\"T Yolo =\", time.time() - start ) \n",
    "    lst.append(time.time() - start)\n",
    "        \n",
    "print(\"AverageGetImage =\", sum(lst2) / len(lst2) ) \n",
    "print(\"AverageYolo =\", sum(lst) / len(lst) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#40fps fullscreen quality3 AverageAll = 0.105, AverageGetImage = 0.0021\n",
    "\n",
    "#over lan 35fps fullscreen quality3\n",
    "#AverageGetImage = 0.019696117627738725\n",
    "#AverageAll = 0.09919774414289116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timeout = time.time() + 5 #5 secs\n",
    "\n",
    "while True:\n",
    "    if time.time() > timeout:\n",
    "        break\n",
    "    x = 0\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        responses = client.simGetImages([ airsim.ImageRequest(\"0\", airsim.ImageType.Scene, False, False) ])\n",
    "        response = responses[0]\n",
    "        #detected = get_pred((np.frombuffer(response.image_data_uint8, dtype=np.uint8) ).reshape(response.height, response.width, 4))\n",
    "        if(time.time() - start > 1):\n",
    "            break\n",
    "        x += 1\n",
    "\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHOW ONE IMAEG\n",
    "png_image = BADAS_fns.client.simGetImage(\"0\", BADAS_fns.airsim.ImageType.Scene)\n",
    "Image.open(io.BytesIO(png_image)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mss\n",
    "import mss.tools\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    with mss.mss() as sct:\n",
    "        for num, monitor in enumerate(sct.monitors[1:], 1):\n",
    "            # Get raw pixels from the screen\n",
    "            sct_img = sct.grab(monitor)\n",
    "            # Create the Image\n",
    "            img = Image.frombytes(\"RGB\", sct_img.size, sct_img.bgra, \"raw\", \"BGRX\")\n",
    "\n",
    "        # Grab the data\n",
    "        t = time.time()\n",
    "        sct_img = sct.grab(monitor)\n",
    "        print(time.time() - t)\n",
    "        #sct_img.\n",
    "        #print(type(sct_img))\n",
    "        # Save to the picture file\n",
    "        #mss.tools.to_png(sct_img.rgb, sct_img.size, output=output)\n",
    "        #print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = client.simGetImages([ airsim.ImageRequest(\"0\", airsim.ImageType.Scene, False, False) ])\n",
    "response = responses[0]\n",
    "img1d = np.fromstring(response.image_data_uint8, dtype=np.uint8) \n",
    "img_rgba = img1d.reshape(response.height, response.width, 4)  \n",
    "img_RGB = cv2.cvtColor(img_rgba, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('3.jpg',img_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMonitorImg():\n",
    "    with mss.mss() as sct:\n",
    "        for num, monitor in enumerate(sct.monitors[1:], 1):\n",
    "            # Get raw pixels from the screen\n",
    "            sct_img = sct.grab(monitor)\n",
    "            # Create the Image\n",
    "            return Image.frombytes(\"RGB\", sct_img.size, sct_img.bgra, \"raw\", \"BGRX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMonitorImg2():\n",
    "    with mss.mss() as sct:\n",
    "        monitor = {\"top\": 0, \"left\": 0, \"width\": 1920, \"height\": 1040}\n",
    "        img = numpy.array(sct.grab(monitor))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "get_pred(img)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('imgs/noshade500x208.JPG')\n",
    "# H, x_pixels_per_meter, y_pixels_per_meter = driver_perspective_transform(img, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BADAS_fns.StopBrake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 50\n",
    "h = 500\n",
    "\n",
    "x= 100\n",
    "w= 300\n",
    "\n",
    "print(img.shape)\n",
    "newim = img[y:y+h, x:x+w]\n",
    "print(newim.shape)\n",
    "cv2.imshow(\"cropped\", newim)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('imgs/noshade1200x500.JPG')\n",
    "\n",
    "y,x,z = img.shape\n",
    "cropx = 320\n",
    "startx = x//2-(cropx//2)\n",
    "starty = y\n",
    "img = img[y - 420: y,startx:startx+cropx]\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('imgs/noshade1200x500.JPG')\n",
    "y,x,z = img.shape\n",
    "# img = img[y - 500: y, x - 700: x]\n",
    "\n",
    "t =time.time() \n",
    "pred, top_left, bottom_right, labels = get_pred(img)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgYOLO = crop_center(img,600,600)\n",
    "cv2.imshow(\"img\", imgYOLO)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, top_left, bottom_right, labels = get_pred(imgYOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
